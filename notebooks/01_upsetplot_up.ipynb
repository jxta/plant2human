{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import requests\n",
    "import requests.exceptions\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from upsetplot import UpSet, from_memberships\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Create output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "#output directory\n",
    "direction = \"up\"\n",
    "species = \"rice\"\n",
    "now = datetime.datetime.now()\n",
    "result = Path(f'../out/upsetplot_{direction}_{now.strftime(\"%y%m\")}_{species}')\n",
    "result.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Gene Ontology information\n",
    "\n",
    "- GOSlimのタームであるGO:0006950 response to stressがアノテーションされているか\n",
    "- アノテーションされている場合、マッピングされたGOのエビデンスコードがIEAのみかを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goslim_mapping = pl.read_csv(\n",
    "    \"../Data/Data_quickgo/240628/QuickGO_rice_all_goslim_mapping_up_upsetplot_v2.tsv\", separator=\"\\t\"\n",
    ").drop(\n",
    "    [\"Entry\", \"GOSlim\", \"SLIMMED FROM\", \"GO EVIDENCE CODE\"]\n",
    ").with_columns( # アノテーションされたGOのエビデンスコードがIEAのみの場合は、response to stressをNoneにする(upsetplotのため)\n",
    "    pl.when(\n",
    "        pl.col(\"response to stress (only IEA)\").is_not_null()\n",
    "    ).then(\n",
    "        None\n",
    "    ).otherwise(\n",
    "        pl.col(\"response to stress\")\n",
    "    ).alias(\"response to stress\")\n",
    ")\n",
    "\n",
    "display(goslim_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフレームをPandasに変換\n",
    "goslim_mapping_pd = goslim_mapping.to_pandas()\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# convert to dict for upsetplot\n",
    "membership_dict = {}\n",
    "for index, row in goslim_mapping_pd.iterrows():\n",
    "    membership_list = []\n",
    "    for col in goslim_mapping_pd.columns[1:]:\n",
    "        if row[col] is not None:\n",
    "            membership_list.append(col)\n",
    "    membership_dict[row[\"From\"]] = membership_list\n",
    "\n",
    "# upsetplot用のデータに変換\n",
    "upset_data = from_memberships(membership_dict.values())\n",
    "\n",
    "# upsetplotを使用して可視化\n",
    "upset_plot = UpSet(upset_data, \n",
    "                   orientation='horizontal',\n",
    "                   show_counts=\"{:d}\",\n",
    "                   subset_size='count', \n",
    "                   include_empty_subsets = False)\n",
    "\n",
    "# スタイルの設定\n",
    "upset_plot.style_subsets(present=\"response to stress\", \n",
    "                         facecolor=\"red\"\n",
    "                         )\n",
    "\n",
    "upset_plot.style_subsets(present=\"response to stress (only IEA)\", \n",
    "                         facecolor=\"red\"\n",
    "                         )\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8), dpi=500)\n",
    "upset_plot.plot(fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) InterPro and Ortholog information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_id = pl.read_csv(\"../Data/Data_uniprot/id_mapping_result/202404/HN5_rice_up_idmapping_complete.tsv\", separator=\"\\t\").sort(\"From\").with_columns(pl.col(\"AlphaFoldDB\").str.replace(\";\", \"\"))\n",
    "\n",
    "# Remove all \"null\" columns https://docs.pola.rs/py-polars/html/reference/dataframe/api/polars.DataFrame.drop_nulls.html\n",
    "uniprot_id = uniprot_id[[s.name for s in uniprot_id if not (s.null_count() == uniprot_id.height)]]\n",
    "\n",
    "# if any ortholog database exists, fill with \"Ortholog DB\" in \"Ortholog DB\" column\n",
    "uniprot_id = uniprot_id.with_columns(\n",
    "    (\n",
    "        pl.col(\"OrthoDB\").is_not_null() |\n",
    "        pl.col(\"OMA\").is_not_null() |\n",
    "        pl.col(\"eggNOG\").is_not_null() |\n",
    "        pl.col(\"InParanoid\").is_not_null() |\n",
    "        pl.col(\"HOGENOM\").is_not_null()\n",
    "    ).map_elements(lambda x: \"Ortholog DB\" if x else None, return_dtype=pl.Utf8).alias(\"Ortholog DB\")\n",
    ")\n",
    "\n",
    "#Set Review column to null where value is \"unreviewed\"\n",
    "uniprot_id = uniprot_id.with_columns(\n",
    "    pl.when(pl.col(\"Reviewed\") == \"unreviewed\")\n",
    "    .then(None)\n",
    "    .otherwise(pl.col(\"Reviewed\"))\n",
    "    .alias(\"Reviewed\")\n",
    ")\n",
    "\n",
    "# this dataframe is used for upsetplot\n",
    "uniprot_id_select = uniprot_id.select([\n",
    "    \"From\",\n",
    "    \"Entry\",\n",
    "    #\"Reviewed\",\n",
    "    \"InterPro\",\n",
    "    \"Ortholog DB\"\n",
    "])\n",
    "\n",
    "print(uniprot_id.group_by(\"Entry\").n_unique())\n",
    "display(uniprot_id_select.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_row_with_values(df):\n",
    "    #reviewed_not_null = df.filter(pl.col(\"Reviewed\").is_not_null())\n",
    "    #if not reviewed_not_null.is_empty():\n",
    "    #    df = reviewed_not_null\n",
    "    \n",
    "    ortholog_db_not_null = df.filter(pl.col(\"Ortholog DB\").is_not_null())\n",
    "    if not ortholog_db_not_null.is_empty():\n",
    "        df = ortholog_db_not_null\n",
    "    \n",
    "    return df.head(1)\n",
    "\n",
    "# retrieve unique value from uniprot_id_select dataframe\n",
    "unique_from_values = uniprot_id_select.select(\"From\").unique().to_series()\n",
    "\n",
    "# apply select_row_with_values function to unique gene ID\n",
    "selected_rows = []\n",
    "for from_value in unique_from_values:\n",
    "    group_df = uniprot_id_select.filter(pl.col(\"From\") == from_value)\n",
    "    selected_row = select_row_with_values(group_df)\n",
    "    selected_rows.append(selected_row)\n",
    "\n",
    "# join the dataframe\n",
    "uniprot_id_select_filtered = pl.concat(selected_rows).sort(\"From\").drop(\"Entry\")\n",
    "\n",
    "# join the dataframe with goslim_mapping\n",
    "uniprot_id_select_filtered_go = uniprot_id_select_filtered.join(\n",
    "    goslim_mapping,\n",
    "    on=\"From\",\n",
    "    how=\"left\",\n",
    "    coalesce=True\n",
    ")\n",
    "\n",
    "display(uniprot_id_select_filtered_go)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsetplot visualization (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_data_pd = uniprot_id_select_filtered_go.to_pandas()\n",
    "\n",
    "# convert to dict for upsetplot\n",
    "membership_dict = {}\n",
    "for index, row in uniprot_data_pd.iterrows():\n",
    "    membership_list = []\n",
    "    for col in uniprot_data_pd.columns[1:]:\n",
    "        if row[col] is not None:\n",
    "            membership_list.append(col)\n",
    "    membership_dict[row[\"From\"]] = membership_list\n",
    "\n",
    "upset_data = from_memberships(membership_dict.values())\n",
    "\n",
    "upset_plot = UpSet(upset_data, \n",
    "                   orientation='horizontal',\n",
    "                   show_counts=\"{:d}\",\n",
    "                   subset_size='count', \n",
    "                   include_empty_subsets = False)\n",
    "\n",
    "upset_plot.style_subsets(present=\"response to stress\",\n",
    "                         facecolor=\"red\"\n",
    "                         )\n",
    "\n",
    "upset_plot.style_subsets(present=\"response to stress (only IEA)\",\n",
    "                         facecolor=\"red\"\n",
    "                         )\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8), dpi=500)\n",
    "upset_plot.plot(fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Get sequence similarity informartion from ensembl pan-homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pan_homology(dataframe, target_taxon: int, json_file: str):\n",
    "    cache = load_cache(json_file)\n",
    "    search_result = Path(f'{result}/pan_homology_{target_taxon}')\n",
    "    search_result.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def get_id(row):\n",
    "        gene_id = row[0]\n",
    "        if gene_id in cache:\n",
    "            return cache[gene_id]\n",
    "        \n",
    "        request_url = f\"https://rest.ensembl.org/homology/id/oryza_sativa/{gene_id}?compara=pan_homology&content-type=application/json;target_taxon={target_taxon}\"\n",
    "\n",
    "        try:\n",
    "            response = requests.get(request_url, headers={\"Accept\": \"application/json\"}, timeout=30)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                data = json.loads(response.text)\n",
    "                file_name = f'{search_result}/pan_homology_{gene_id}.json'\n",
    "                \n",
    "                if data[\"data\"] and any(\"homologies\" in d for d in data[\"data\"]): #\n",
    "                    human_gene_ids = []\n",
    "                    for entry in data[\"data\"]:\n",
    "                        for homology in entry[\"homologies\"]:\n",
    "                            if homology[\"target\"][\"taxon_id\"] == target_taxon:\n",
    "                                human_gene_ids.append(homology[\"target\"][\"id\"])\n",
    "                            elif homology[\"source\"][\"taxon_id\"] == target_taxon:\n",
    "                                human_gene_ids.append(homology[\"source\"][\"id\"])\n",
    "                    human_gene_ids_str = \",\".join(human_gene_ids)\n",
    "                    cache[gene_id] = human_gene_ids_str\n",
    "                    with open(file_name, \"w\") as f:\n",
    "                        json.dump(data, f, indent=4)\n",
    "                    save_cache(cache, json_file)\n",
    "                    return human_gene_ids_str if human_gene_ids_str else None\n",
    "                else:\n",
    "                    cache[gene_id] = None\n",
    "                    save_cache(cache, json_file)\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"Failed to fetch data for {gene_id}\")\n",
    "                return None\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            return None\n",
    "        finally:\n",
    "            time.sleep(5)\n",
    "    \n",
    "    pan_homology = dataframe.map_rows(get_id, return_dtype = pl.String)\n",
    "    dataframe = dataframe.with_columns(\n",
    "        pl.Series(pan_homology).alias(\n",
    "            f\"pan_homology_{target_taxon}\"\n",
    "            )\n",
    "        )\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan_homology_human = get_pan_homology(uniprot_id_select_filtered_go, 9606, \"cache_pan_homology_human_up.json\")\n",
    "\n",
    "pan_homology_human = pan_homology_human.with_columns(\n",
    "    pl.when(pl.col(\"pan_homology_9606\") == \"\")\n",
    "    .then(None)\n",
    "    .otherwise(pl.col(\"pan_homology_9606\"))\n",
    "    .alias(\"pan-homology human\")\n",
    ").drop(\"pan_homology_9606\")\n",
    "\n",
    "display(pan_homology_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan_homology_mouse = get_pan_homology(pan_homology_human, 10090, \"cache_pan_homology_mouse_up.json\")\n",
    "\n",
    "pan_homology_mouse = pan_homology_mouse.with_columns(\n",
    "    pl.when(pl.col(\"pan_homology_10090\") == \"\")\n",
    "    .then(None)\n",
    "    .otherwise(pl.col(\"pan_homology_10090\"))\n",
    "    .alias(\"pan-homology mouse\")\n",
    ").drop(\"pan_homology_10090\")\n",
    "\n",
    "display(pan_homology_mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan_homology_mouse_pd = pan_homology_mouse.to_pandas()\n",
    "\n",
    "# convert to dict for upsetplot\n",
    "membership_dict = {}\n",
    "for index, row in pan_homology_mouse_pd.iterrows():\n",
    "    membership_list = []\n",
    "    for col in pan_homology_mouse_pd.columns[1:]:\n",
    "        if row[col] is not None:\n",
    "            membership_list.append(col)\n",
    "    membership_dict[row[\"From\"]] = membership_list\n",
    "\n",
    "upset_data = from_memberships(membership_dict.values())\n",
    "\n",
    "upset_plot = UpSet(upset_data, \n",
    "                   orientation='horizontal',\n",
    "                   show_counts=\"{:d}\",\n",
    "                   subset_size='count', \n",
    "                   include_empty_subsets = False)\n",
    "\n",
    "# Highlighting selected subsets\n",
    "# 1. all combination\n",
    "upset_plot.style_subsets(present=\"response to stress\",\n",
    "                         facecolor=\"red\"\n",
    "                         )\n",
    "\n",
    "upset_plot.style_subsets(present=\"response to stress (only IEA)\",\n",
    "                         facecolor=\"red\"\n",
    "                         )\n",
    "\n",
    "\n",
    "# 2. response to stress\n",
    "upset_plot.style_subsets(\n",
    "    present=\"response to stress\",\n",
    "    absent=[\"pan-homology human\", \"pan-homology mouse\"],\n",
    "    facecolor=\"coral\"\n",
    ")\n",
    "\n",
    "upset_plot.style_subsets(\n",
    "    present=\"response to stress (only IEA)\",\n",
    "    absent=[\"pan-homology human\", \"pan-homology mouse\"],\n",
    "    facecolor=\"coral\"\n",
    ")\n",
    "\n",
    "# 3. pan-homology\n",
    "upset_plot.style_subsets(\n",
    "    present=[\"pan-homology human\", \"pan-homology mouse\"],\n",
    "    absent=[\"response to stress\", \"response to stress (only IEA)\"],\n",
    "    facecolor=\"forestgreen\"\n",
    ")\n",
    "\n",
    "# 4. InterPro and Ortholog DB\n",
    "upset_plot.style_subsets(\n",
    "    present=[\"InterPro\", \"Ortholog DB\"],\n",
    "    absent=[\"response to stress\", \"response to stress (only IEA)\", \"pan-homology human\", \"pan-homology mouse\"],\n",
    "    facecolor=\"navy\"\n",
    ")\n",
    "\n",
    "fig_3 = plt.figure(figsize=(16, 10), dpi=700)\n",
    "upset_plot.plot(fig=fig_3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Patch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create legend independently\u001b[39;00m\n\u001b[1;32m      2\u001b[0m legend_elements \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mPatch\u001b[49m(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse to stress\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      4\u001b[0m     Patch(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoral\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse to stress (no pan-homology information)\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      5\u001b[0m     Patch(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforestgreen\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpan-homology\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      6\u001b[0m     Patch(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnavy\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterPro and Ortholog DB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m ]\n\u001b[1;32m      9\u001b[0m fig_leg \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m), dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m     10\u001b[0m ax_leg \u001b[38;5;241m=\u001b[39m fig_leg\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m111\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Patch' is not defined"
     ]
    }
   ],
   "source": [
    "# Create legend independently\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"red\", label=\"response to stress\"),\n",
    "    Patch(facecolor='coral', label='response to stress (no pan-homology information)'),\n",
    "    Patch(facecolor='forestgreen', label='pan-homology'),\n",
    "    Patch(facecolor=\"navy\", label=\"InterPro and Ortholog DB\")\n",
    "]\n",
    "\n",
    "fig_leg = plt.figure(figsize=(1.5, 0.5), dpi=500)\n",
    "ax_leg = fig_leg.add_subplot(111)\n",
    "ax_leg.legend(handles=legend_elements, loc='center')\n",
    "ax_leg.axis('off') \n",
    "plt.show()\n",
    "# fig_leg.savefig('legend.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "pan_homology_mouse.write_csv(\n",
    "    f\"{result}/upsetplot_data_rice_up.tsv\", separator=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Classification and download mmCIF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cif_afurl(dataframe, json_file: str,):\n",
    "    cache = load_cache(json_file)\n",
    "\n",
    "    def get_url(row):\n",
    "        alpha_fold_id = row[1] # alphafold DBとクロスリファレンスがうまくいっていないが､構造があるIDがあるため､それらを取得するためEntryカラムに設定\n",
    "        if alpha_fold_id is None or alpha_fold_id == \"\":\n",
    "            return None\n",
    "\n",
    "        if alpha_fold_id in cache:\n",
    "            return cache[alpha_fold_id]\n",
    "        \n",
    "        request_url = f'https://alphafold.ebi.ac.uk/api/prediction/{alpha_fold_id}'\n",
    "\n",
    "        try:\n",
    "            response = requests.get(request_url, headers={\"Accept\": \"application/json\"}, timeout=30)\n",
    "            response.raise_for_status()\n",
    "    \n",
    "            if response.text:\n",
    "                data = json.loads(response.text)\n",
    "                if isinstance(data, list) and len(data) > 0: \n",
    "                    print(f\"AlphaFold ID {alpha_fold_id} found in AlphaFold\")\n",
    "                    cif_url = data[0].get('cifUrl', None)\n",
    "                    cache[alpha_fold_id] = cif_url\n",
    "                    save_cache(cache, json_file)\n",
    "                    return cif_url\n",
    "                else:\n",
    "                    print(f\"AlphaFold ID {alpha_fold_id} not found in AlphaFold\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"Empty response for AlphaFold ID {alpha_fold_id}\")\n",
    "                return None\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "        time.sleep(5)\n",
    "        return None\n",
    "    \n",
    "  \n",
    "    url = dataframe.map_rows(get_url, return_dtype = pl.String) # specify return_dtype to avoid error (in this case, pl.Boolean)\n",
    "    dataframe = dataframe.with_columns(\n",
    "        pl.Series(url).alias(\n",
    "            \"mmCIFfile_AF_URL\"\n",
    "            )\n",
    "        )\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mmCIF_files(dataframe, target_directory='../rice_up_mmCIFfile'):\n",
    "    os.makedirs(target_directory, exist_ok=True)\n",
    "    URL_col = dataframe.select(\"mmCIFfile_AF_URL\").get_columns()[0]\n",
    "\n",
    "    #retrieve mmCIF file from url\n",
    "    for url in URL_col:\n",
    "        if url and url != 'URL not found':\n",
    "            filename = url.split('/')[-1] # get the last element\n",
    "            save_path = os.path.join(target_directory, filename)\n",
    "\n",
    "            if not os.path.exists(save_path): # if file not exists, download it\n",
    "                response = requests.get(url)\n",
    "                if response.status_code == 200:\n",
    "                    with open(save_path, 'wb') as f:\n",
    "                        f.write(response.content)\n",
    "                    print(f'File {filename} downloaded successfully')\n",
    "                    time.sleep(10)\n",
    "                else:\n",
    "                    print(f'Failed to download {filename}, HTTP Status Code: {response.status_code}')\n",
    "            else:\n",
    "                print(f'File {filename} already exists')\n",
    "        else:\n",
    "            print(f'Skipping invalid or missing URL, URL: {url}')\n",
    "            \n",
    "\n",
    "def extract_filename(url):\n",
    "    return url.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. response to stress\n",
    "all_combination = pan_homology_mouse.filter(\n",
    "    (pl.col(\"InterPro\").is_not_null()) & \n",
    "    (pl.col(\"Ortholog DB\").is_not_null()) &\n",
    "    (pl.col(\"pan-homology human\").is_not_null()) &\n",
    "    (pl.col(\"pan-homology mouse\").is_not_null()) &\n",
    "    ((pl.col(\"response to stress\").is_not_null()) |\n",
    "    (pl.col(\"response to stress (only IEA)\").is_not_null()))\n",
    ").join(\n",
    "    uniprot_id,\n",
    "    on=\"From\",\n",
    "    how=\"left\",\n",
    "    coalesce=True\n",
    ").select(\n",
    "    [\n",
    "        \"From\",\n",
    "        \"Entry\",\n",
    "        \"Reviewed\",\n",
    "        \"AlphaFoldDB\",\n",
    "        \"Protein families\",\n",
    "        \"InterPro\",\n",
    "        \"Ortholog DB\",\n",
    "        \"pan-homology human\",\n",
    "        \"pan-homology mouse\",\n",
    "        \"response to stress\",\n",
    "        \"response to stress (only IEA)\"\n",
    "    ]\n",
    ").with_columns(\n",
    "    pl.lit(\"response_to_stress\").alias(\"tag\")\n",
    ")\n",
    "\n",
    "print(all_combination.group_by([\"From\"]).n_unique()) # Check gene count\n",
    "\n",
    "#download mmCIF file\n",
    "all_combination = get_cif_afurl(all_combination, \"cache_af_url.json\")\n",
    "download_mmCIF_files(all_combination)\n",
    "\n",
    "display(all_combination.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. response to stress (no pan-homology information)\n",
    "response_to_stress = pan_homology_mouse.filter(\n",
    "    ((pl.col(\"response to stress\").is_not_null()) |\n",
    "    (pl.col(\"response to stress (only IEA)\").is_not_null())) &\n",
    "    (~pl.col(\"pan-homology human\").is_not_null()) &\n",
    "    (~pl.col(\"pan-homology mouse\").is_not_null())\n",
    ").join(\n",
    "    uniprot_id,\n",
    "    on=\"From\",\n",
    "    how=\"left\",\n",
    "    coalesce=True\n",
    ").select(\n",
    "    [\n",
    "        \"From\",\n",
    "        \"Entry\",\n",
    "        \"Reviewed\",\n",
    "        \"AlphaFoldDB\",\n",
    "        \"Protein families\",\n",
    "        \"InterPro\",\n",
    "        \"Ortholog DB\",\n",
    "        \"pan-homology human\",\n",
    "        \"pan-homology mouse\",\n",
    "        \"response to stress\",\n",
    "        \"response to stress (only IEA)\"\n",
    "    ]\n",
    ").with_columns(\n",
    "    pl.lit(\"response_to_stress_no_panhomology\").alias(\"tag\")\n",
    ")\n",
    "\n",
    "print(response_to_stress.group_by([\"From\"]).n_unique()) # Check gene count\n",
    "\n",
    "# download mmCIF file\n",
    "only_response_to_stress = get_cif_afurl(response_to_stress, \"cache_af_url.json\")\n",
    "download_mmCIF_files(only_response_to_stress)\n",
    "\n",
    "display(only_response_to_stress.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. pan-homology\n",
    "pan_homology = pan_homology_mouse.filter(\n",
    "    (pl.col(\"response to stress\").is_null()) &\n",
    "    (pl.col(\"response to stress (only IEA)\").is_null()) &\n",
    "    (pl.col(\"pan-homology human\").is_not_null()) &\n",
    "    (pl.col(\"pan-homology mouse\").is_not_null())\n",
    ").join(\n",
    "    uniprot_id,\n",
    "    on=\"From\",\n",
    "    how=\"left\",\n",
    "    coalesce=True\n",
    ").select(\n",
    "    [\n",
    "        \"From\",\n",
    "        \"Entry\",\n",
    "        \"Reviewed\",\n",
    "        \"AlphaFoldDB\",\n",
    "        \"Protein families\",\n",
    "        \"InterPro\",\n",
    "        \"Ortholog DB\",\n",
    "        \"pan-homology human\",\n",
    "        \"pan-homology mouse\",\n",
    "        \"response to stress\",\n",
    "        \"response to stress (only IEA)\"\n",
    "    ]\n",
    ").with_columns(\n",
    "    pl.lit(\"panhomology\").alias(\"tag\")\n",
    ")\n",
    "\n",
    "print(pan_homology.group_by([\"From\"]).n_unique()) # Check gene count\n",
    "pan_homology = get_cif_afurl(pan_homology, \"cache_af_url.json\")\n",
    "download_mmCIF_files(pan_homology)\n",
    "\n",
    "display(pan_homology.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. InterPro and Ortholog DB\n",
    "interpro_orthologdb = pan_homology_mouse.filter(\n",
    "    (pl.col(\"InterPro\").is_not_null()) &\n",
    "    (pl.col(\"Ortholog DB\").is_not_null()) &\n",
    "    (pl.col(\"pan-homology human\").is_null()) &\n",
    "    (pl.col(\"pan-homology mouse\").is_null()) &\n",
    "    ((pl.col(\"response to stress\").is_null()) &\n",
    "    (pl.col(\"response to stress (only IEA)\").is_null()))\n",
    ").join(\n",
    "    uniprot_id,\n",
    "    on=\"From\",\n",
    "    how=\"left\",\n",
    "    coalesce=True\n",
    ").select(\n",
    "    [\n",
    "        \"From\",\n",
    "        \"Entry\",\n",
    "        \"Reviewed\",\n",
    "        \"AlphaFoldDB\",\n",
    "        \"Protein families\",\n",
    "        \"InterPro\",\n",
    "        \"Ortholog DB\",\n",
    "        \"pan-homology human\",\n",
    "        \"pan-homology mouse\",\n",
    "        \"response to stress\",\n",
    "        \"response to stress (only IEA)\"\n",
    "    ]\n",
    ").with_columns(\n",
    "    pl.lit(\"interpro_orthologdb\").alias(\"tag\")\n",
    ")\n",
    "\n",
    "print(interpro_orthologdb.group_by([\"From\"]).n_unique()) # Check gene count\n",
    "\n",
    "# download mmCIF file\n",
    "interpro_orthologdb = get_cif_afurl(interpro_orthologdb, \"cache_af_url.json\")\n",
    "display(interpro_orthologdb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Only InterPro\n",
    "only_interpro = pan_homology_mouse.filter(\n",
    "    (pl.col(\"InterPro\").is_not_null()) &\n",
    "    (pl.col(\"Ortholog DB\").is_null()) &\n",
    "    (pl.col(\"pan-homology human\").is_null()) &\n",
    "    (pl.col(\"pan-homology mouse\").is_null()) &\n",
    "    (pl.col(\"response to stress\").is_null()) &\n",
    "    (pl.col(\"response to stress (only IEA)\").is_null())\n",
    ").join(\n",
    "    uniprot_id,\n",
    "    on=\"From\",\n",
    "    how=\"left\",\n",
    "    coalesce=True\n",
    ").select(\n",
    "    [\n",
    "        \"From\",\n",
    "        \"Entry\",\n",
    "        \"Reviewed\",\n",
    "        \"AlphaFoldDB\",\n",
    "        \"Protein families\",\n",
    "        \"InterPro\",\n",
    "        \"Ortholog DB\",\n",
    "        \"pan-homology human\",\n",
    "        \"pan-homology mouse\",\n",
    "        \"response to stress\",\n",
    "        \"response to stress (only IEA)\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 6. Only ortholog DB\n",
    "only_orthologdb = pan_homology_mouse.filter(\n",
    "    (pl.col(\"InterPro\").is_null()) &\n",
    "    (pl.col(\"Ortholog DB\").is_not_null()) &\n",
    "    (pl.col(\"pan-homology human\").is_null()) &\n",
    "    (pl.col(\"pan-homology mouse\").is_null()) &\n",
    "    ((pl.col(\"response to stress\").is_null()) &\n",
    "    (pl.col(\"response to stress (only IEA)\").is_null()))\n",
    ").join(\n",
    "    uniprot_id,\n",
    "    on=\"From\",\n",
    "    how=\"left\",\n",
    "    coalesce=True\n",
    ").select(\n",
    "    [\n",
    "        \"From\",\n",
    "        \"Entry\",\n",
    "        \"Reviewed\",\n",
    "        \"AlphaFoldDB\",\n",
    "        \"Protein families\",\n",
    "        \"InterPro\",\n",
    "        \"Ortholog DB\",\n",
    "        \"pan-homology human\",\n",
    "        \"pan-homology mouse\",\n",
    "        \"response to stress\",\n",
    "        \"response to stress (only IEA)\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "only_information = pl.concat(\n",
    "    [only_interpro, only_orthologdb]\n",
    ").with_columns(\n",
    "    pl.lit(\"only_information\").alias(\"tag\")\n",
    ")\n",
    "\n",
    "print(only_information.group_by([\"From\"]).n_unique()) # Check gene count\n",
    "# download mmCIF file\n",
    "only_information = get_cif_afurl(only_information, \"cache_af_url.json\")\n",
    "display(only_information.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_information = pl.concat([\n",
    "    all_combination,\n",
    "    only_response_to_stress,\n",
    "    pan_homology,\n",
    "    interpro_orthologdb,\n",
    "    only_information\n",
    "]).sort(\n",
    "    \"From\"\n",
    ")\n",
    "print(all_information.group_by([\"From\"]).n_unique()) # Check gene count\n",
    "display(all_information.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HNscore_up = pl.read_csv(\n",
    "    \"../Data/Data_HN5_genelist_rice_2402/HN5_genes_up_rice.tsv\",\n",
    "    separator=\"\\t\"\n",
    ")\n",
    "\n",
    "all_information_score = all_information.join(\n",
    "    HNscore_up,\n",
    "    on=\"From\",\n",
    "    how=\"left\",\n",
    "    coalesce=True\n",
    ").unique()\n",
    "\n",
    "grouped = all_information_score.group_by(\"From\").agg(\n",
    "    pl.col(\"AlphaFoldDB\").map_elements(lambda x: x.is_null().all()).alias(\"all_null\")\n",
    ").filter(pl.col(\"all_null\")).select(\"From\").write_csv(\"./noaf.tsv\", separator=\"\\t\")\n",
    "\n",
    "\n",
    "print(all_information_score.group_by([\"From\"]).n_unique())\n",
    "print(all_information_score.group_by([\"Entry\"]).n_unique())\n",
    "display(all_information_score.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combination.write_csv(f\"{result}/response_to_stress.tsv\", separator=\"\\t\")\n",
    "only_response_to_stress.write_csv(f\"{result}/response_to_stress_no_panhomology.tsv\", separator=\"\\t\")\n",
    "pan_homology.write_csv(f\"{result}/panhomology.tsv\", separator=\"\\t\")\n",
    "interpro_orthologdb.write_csv(f\"{result}/interpro_orthologdb.tsv\", separator=\"\\t\")\n",
    "only_information.write_csv(f\"{result}/only_one_information.tsv\", separator=\"\\t\")\n",
    "all_information_score.write_csv(f\"{result}/all_information_score.tsv\", separator=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
